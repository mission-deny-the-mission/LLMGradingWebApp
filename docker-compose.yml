#version: "3"
services:
  llmgradingwebapp:
    build: .
    container_name: llmgradingwebapp
    volumes:
      - ./instance:/usr/src/app/instance
      - ./uploads:/usr/src/app/uploads
      - ./results:/usr/src/app/results
    ports:
      - 8000:8000

  celery:
    build: .
    container_name: celery
    command: celery -A run.celery worker --loglevel=info
    volumes:
      - ./instance:/usr/src/app/instance
      - ./uploads:/usr/src/app/uploads
      - ./results:/usr/src/app/results

  ollama:
    image: ollama/ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    container_name: ollama
    volumes:
      - /var/home/harry/.ollama:/root/.ollama

  redis:
    image: redis

#volumes:
#  ollama: {}